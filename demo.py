from CorpusReader import CorpusReader


data = CorpusReader('data/train-set.txt')

print(data)

# for key, item in data.items():
#     print(tokenized_words(item['Sentence1']))
