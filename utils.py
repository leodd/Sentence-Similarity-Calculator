from nltk.tokenize import word_tokenize


def tokenized_words(s):
    return word_tokenize(s)
